{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e36cc26-7987-4907-8dc1-d5ffb17f81af",
   "metadata": {},
   "source": [
    "# Project 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80748edc-5ba3-4eab-b341-54dbddf1af97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: keras in /opt/anaconda3/lib/python3.12/site-packages (3.7.0)\n",
      "Requirement already satisfied: opencv-python in /opt/anaconda3/lib/python3.12/site-packages (4.10.0.84)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras) (13.3.5)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.12/site-packages (from keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.12/site-packages (from keras) (0.13.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow keras opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f920f99-2d82-4fc9-92e8-5e9a9764fe5b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40a04884-f487-4924-aa65-ee6bb5289642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# general i.o & math imports\n",
    "import cv2 as cv\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# nn imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20ed633",
   "metadata": {},
   "source": [
    "# Introducing our Rice Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ead2d3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bfb40bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/devamin/Desktop/3162-FinalProject/riceImages/Arborio/Arborio (1).jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m imgArb \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mriceImages/Arborio/Arborio (1).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m imgBas \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mriceImages/Basmati/Basmati (1).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m imgIps \u001b[38;5;241m=\u001b[39m mpimg\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mriceImages/Ipsala/Ipsala (1).jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/matplotlib/image.py:1525\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1518\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fname, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parse\u001b[38;5;241m.\u001b[39murlparse(fname)\u001b[38;5;241m.\u001b[39mscheme) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1519\u001b[0m     \u001b[38;5;66;03m# Pillow doesn't handle URLs directly.\u001b[39;00m\n\u001b[1;32m   1520\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1521\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1522\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1523\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1524\u001b[0m         )\n\u001b[0;32m-> 1525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_open(fname) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[1;32m   1527\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1528\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/PIL/Image.py:3277\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3274\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3276\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3277\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3278\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3280\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/devamin/Desktop/3162-FinalProject/riceImages/Arborio/Arborio (1).jpg'"
     ]
    }
   ],
   "source": [
    "imgArb = mpimg.imread(\"riceImagesSmall/Arborio/Arborio (1).jpg\")\n",
    "imgBas = mpimg.imread(\"riceImagesSmall/Basmati/Basmati (1).jpg\")\n",
    "imgIps = mpimg.imread(\"riceImagesSmall/Ipsala/Ipsala (1).jpg\")\n",
    "imgJas = mpimg.imread(\"riceImagesSmall/Jasmine/Jasmine (1).jpg\")\n",
    "imgKar = mpimg.imread(\"riceImagesSmall/Karacadag/Karacadag (1).jpg\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d7986b",
   "metadata": {},
   "source": [
    "## Arborio Rice\n",
    "\n",
    "Arborio rice is an Italian short-grain rice that is characterized by it's short, fat, and slightly oval shaped grains. On average a grain is about 5 mm in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgArb)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08794e7a",
   "metadata": {},
   "source": [
    "## Basmati Rice\n",
    "\n",
    "Basmati rice is traditionally grown in the Indian subontinent, and is characterized by its long thin shape. It is typically around 6.61 mm in length, and about 2 mm in girth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c418cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgBas)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b77704",
   "metadata": {},
   "source": [
    "## Jasmine Rice\n",
    "\n",
    "Jasmine rice is grown primarily in areas of Southeast Asia, such as Thailand, Cambodia, Laos, and Vietnam. Typically it is around 7 mm in length. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb944fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgJas)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ce77c6",
   "metadata": {},
   "source": [
    "## Ipsala Rice\n",
    "\n",
    "Ipsala rice (also known as Baldo rice) is a short-grain rice grown in Italy and Turkey. It is typically around 7 mm in length, and 3 mm in width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034730ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgIps)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4f2c3b",
   "metadata": {},
   "source": [
    "## Karacadag Rice\n",
    "\n",
    "Karacadag Rice grains are typically 4-6 mm long, and 3-4 mm wide. It hails from the South-Eastern Anatolia region of Turkey, and is named after the dormant volcano located there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e827991",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgKar)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9ef99-312d-4126-9d5e-54e205ba5227",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dbcebac-2dce-41cb-af81-c63afaa4407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALED_IMG_SIZE = (128, 128)\n",
    "BASE_PATH = \"riceImages\"\n",
    "NORMALIZATION_SCALE = 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1713643-3049-4376-8cc4-792993b6bea8",
   "metadata": {},
   "source": [
    "The code below requires that the rice images be in seperate folders in one directory that is in the same directory as the notebook. i.e."
   ]
  },
  {
   "attachments": {
    "d5303d20-c820-4c3a-ad2c-d4117808942d.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "c63196d1-a327-4ffc-bb76-f2c164f17f3b",
   "metadata": {},
   "source": [
    "![riceImages.png](attachment:d5303d20-c820-4c3a-ad2c-d4117808942d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d56680-1358-4707-94cf-9a837c434f9b",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e860c1ad-5551-4d2a-8475-43898d819afc",
   "metadata": {},
   "source": [
    "The dataset contains images of rice placed against a black background. Each class of rice (\"Arborio\", \"Basmati\", etc.) are organized into separate folders, each containing 1,000* images. Our goal here is to preprocess these images and their labels to make them suitable for training a machine learning model.\n",
    "\n",
    "*The original dataset had far more, but we brought them down to a realistic proportion for us to work against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c60863-54cc-4117-b6ac-8c7479eb76af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []   # holds the image data (processed, resized, & normalized as numpy arrays)\n",
    "labels = [] # holds the original string labels (like \"Arborio\", \"Basmati\") for each img\n",
    "\n",
    "for label in os.listdir(BASE_PATH):\n",
    "    folder_path = os.path.join(BASE_PATH, label)\n",
    "    \n",
    "    if os.path.isdir(folder_path):\n",
    "        for image_name in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, image_name)\n",
    "            \n",
    "            image = cv.imread(image_path)\n",
    "            \n",
    "            if image is not None:\n",
    "                image = cv.resize(image, SCALED_IMG_SIZE)\n",
    "                \n",
    "                # normalize image to 0, 1\n",
    "                image = image / NORMALIZATION_SCALE\n",
    "                \n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "\n",
    "# convert the data list to a numpy array\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "\n",
    "# label to int mapping\n",
    "# i.e., mapping might look like this...\n",
    "# \"Arborio\" ->   0\n",
    "# \"Basmati\" ->   1\n",
    "# \"Ipsala\" ->    2\n",
    "# \"Jasmine\" ->   3\n",
    "# \"Karacadag\" -> 4\n",
    "label_encoder = LabelEncoder()\n",
    "labels_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(data, labels_encoded, test_size=0.2)\n",
    "\n",
    "# df\n",
    "df = pd.DataFrame(list(zip(labels, labels_encoded)), columns=[\"label\", \"encoded_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948c4cd-0bed-4f79-ad76-9f801d39e55b",
   "metadata": {},
   "source": [
    "We first loop through each subfolder representing the rice varieties or labels within the main riceImages directory. For each label folder, we then read each image. The images are read using OpenCV (cv.imread()), which loads the image in its original format.\n",
    "\n",
    "Each image is resized to a consistent size of 128x128 pixels using OpenCV’s cv.resize(). We're doing this since neural networks prefer when the images match aspect ratios & dimensions as input.\n",
    "\n",
    "After resizing the image, we normalize the pixel values by dividing the pixel values by 255. This makes sure values are in the range of (0-1). Normalizing the image is also good for helping the model learn more effectively since neural networks tend to converge faster when input data is scaled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1127cec8-bf4e-4a6a-ac7c-21ba9f35c55f",
   "metadata": {},
   "source": [
    "# Modeling (just an example from pre-processing & actually using the data I worked on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545880c0-ff08-4771-8357-734ee40143f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VVV using tensorflow.keras.models here VVV\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))  # 5 classes (may be good just to use the len of labels lol)\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7b0c869-8807-4d23-92d7-0f6bccbf7585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 5 classes.\n",
      "Found 1000 images belonging to 5 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 355ms/step - accuracy: 0.7059 - loss: 0.7268 - val_accuracy: 0.9750 - val_loss: 0.0842\n",
      "Epoch 2/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 327ms/step - accuracy: 0.9569 - loss: 0.1205 - val_accuracy: 0.9610 - val_loss: 0.1207\n",
      "Epoch 3/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 355ms/step - accuracy: 0.9644 - loss: 0.1156 - val_accuracy: 0.9740 - val_loss: 0.0859\n",
      "Epoch 4/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 328ms/step - accuracy: 0.9700 - loss: 0.0934 - val_accuracy: 0.9790 - val_loss: 0.0683\n",
      "Epoch 5/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 322ms/step - accuracy: 0.9764 - loss: 0.0661 - val_accuracy: 0.9850 - val_loss: 0.0508\n",
      "Epoch 6/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 314ms/step - accuracy: 0.9778 - loss: 0.0681 - val_accuracy: 0.9760 - val_loss: 0.0722\n",
      "Epoch 7/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 316ms/step - accuracy: 0.9762 - loss: 0.0624 - val_accuracy: 0.9730 - val_loss: 0.0867\n",
      "Epoch 8/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 318ms/step - accuracy: 0.9784 - loss: 0.0585 - val_accuracy: 0.9770 - val_loss: 0.0594\n",
      "Epoch 9/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 419ms/step - accuracy: 0.9809 - loss: 0.0486 - val_accuracy: 0.9740 - val_loss: 0.0958\n",
      "Epoch 10/10\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 489ms/step - accuracy: 0.9845 - loss: 0.0439 - val_accuracy: 0.9840 - val_loss: 0.0634\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 135ms/step\n",
      "F1 Score: 0.9839983079343857\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Arborio       0.98      0.96      0.97       200\n",
      "     Basmati       1.00      0.98      0.99       200\n",
      "      Ipsala       1.00      0.99      1.00       200\n",
      "     Jasmine       0.98      1.00      0.99       200\n",
      "   Karacadag       0.97      0.98      0.98       200\n",
      "\n",
      "    accuracy                           0.98      1000\n",
      "   macro avg       0.98      0.98      0.98      1000\n",
      "weighted avg       0.98      0.98      0.98      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Define parameters\n",
    "image_size = (128, 128)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "# Data augmentation and normalization\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255.0,   # Normalize pixel values\n",
    "    validation_split=0.2 # Split dataset into training and validation\n",
    ")\n",
    "\n",
    "# Training and validation data generators\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    'riceImagesSmall', # Replace with your dataset path\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    'riceImagesSmall', # Replace with your dataset path\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Model definition\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "val_generator.reset()  # Ensure generator starts from the beginning\n",
    "predictions = model.predict(val_generator)\n",
    "y_pred = np.argmax(predictions, axis=1)\n",
    "y_true = val_generator.classes\n",
    "\n",
    "# Compute F1 score\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Classification report\n",
    "print(classification_report(y_true, y_pred, target_names=list(train_generator.class_indices.keys())))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4247c3-4e5f-4e5c-bc7e-f50e4b0e2b37",
   "metadata": {},
   "source": [
    "The model achieves excellent classification performance across five rice types, with an overall accuracy of 98%.\n",
    "\n",
    "## Key Observations:\n",
    "\n",
    "\n",
    "    Class-Specific Performance:\n",
    "\n",
    "        Basmati and Ipsala have perfect recall and F1-scores, showing no misclassifications.\n",
    "        Arborio and Karacadag have slightly lower recall (0.96 and 0.98), indicating minor misclassifications.\n",
    "        \n",
    "    Overall Performance:\n",
    "\n",
    "        Precision, recall, and F1-scores are consistently high (0.97–1.00) across all classes.\n",
    "        Macro and weighted averages are both 0.98, confirming balanced performance across all rice types.\n",
    "        \n",
    "    Model Robustness:\n",
    "\n",
    "    The model demonstrates excellent generalization with 98% accuracy on the validation set, indicating readiness for practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc437b3a",
   "metadata": {},
   "source": [
    "## Model Visualization\n",
    "\n",
    "Below we'll be making a visualization of how model works. \n",
    "\n",
    "There are a few ways we can do this, but we'll be using visualkeras this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f8d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualkeras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21847111",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualkeras.layered_view(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581eb6c4",
   "metadata": {},
   "source": [
    "Each block in our above visualization of our model corresponds to a layer or operation in our model. The layout helps illustrate the flow of data through our Neural Network and how it condenses as it progresses through it.\n",
    "The first layer is our input data, which has a high number of input images. \n",
    "\n",
    "Layer 1: conv2d - this is where our model learns spacial hierarchies of patterns such as edges, textures, or more complex features in our images.\n",
    "Layer 2: maxpooling2d - this reduces the spatial dimensions of our input data, reducing the computational cost while retaining the most important information from our input data\n",
    "Layers 3 - 6 repeat the first two steps a couple more times.\n",
    "Layer 7: flatten\n",
    "Layer 8: dense\n",
    "Layer 9: dropout\n",
    "Layer 10: dense\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
